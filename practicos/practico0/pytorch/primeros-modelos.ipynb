{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construyendo y entrenando redes neuronales con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from torchviz import make_dot\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 1: modelo simple, con numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa aprender un simple modelo de regresión lineal\n",
    "\n",
    "$$ y = a + bx $$\n",
    "\n",
    "Comenzamos por generar los datos.\n",
    "Son $n=100$ puntos, en donde los *features* vienen representados por algunos valores $x_1,x_2,...$ de`x` y los *labels* por correspondientes valores $y_1,y_2,...$ de `y` dados por\n",
    "\n",
    "$$ y_i = a + bx_i + \\epsilon_i $$\n",
    "\n",
    "donde $a=1$, $b=2$ y $\\epsilon_i \\sim \\mathcal{N}(0,0.1)$ es un número aleatorio generado de una distribución gaussia de media 0 y varianza 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos datos aleatorios\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1) # features\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1) # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de aleatorizar el orden de los puntos, dividimos los datos en un conjunto de entrenamiento (de tamaño 80) y uno de validación (de tamaño 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aleatorizamos el orden de las muestras\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Usamos las primeras 80 muestras para entrenamiento\n",
    "train_idx = idx[:80]\n",
    "# y las que 20 que quedan para validación\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generamos los conjuntos (datasets) de entrenamientos y validación\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualicemos los datasets\n",
    "fig,axes=plt.subplots(1,2)\n",
    "fig.set_size_inches(5.0,3.0)\n",
    "ax = axes[0]\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"training\")\n",
    "ax.scatter(x_train,y_train)\n",
    "ax = axes[1]\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_title(\"validation\")\n",
    "ax.scatter(val_idx,val_idx,c='r')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo último es aprender los valores de los parámetros $a$ y $b$ usados para generar los datos.\n",
    "Para ello consideramos la función de pérdida definida por el Error Cuadrático Medio entre las predicciones $\\hat{y}_i:=y(x_i)$ y los valores labels $y_i$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "L(x,y;a,b) &=& \\frac{1}{n}\\sum_{i=1}^n (y_i-y(x_i))^2 \\\\\n",
    "&=& \\frac{1}{n}\\sum_{i=1}^n (y_i-a-bx_i)^2 \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "Usaremos el método del descenso por el gradiente\n",
    "\n",
    "$$ \\frac{\\partial L^{(t)}}{\\partial a}(x,y;a,b) = -\\frac{2}{n}\\sum_{i=1}^n(y_i-y_i(x_i)) $$\n",
    "\n",
    "$$ \\frac{\\partial L^{(t)}}{\\partial b}(x,y;a,b) = -\\frac{2}{n}\\sum_{i=1}^nx_i(y_i-y_i(x_i)) $$\n",
    "\n",
    "arrancando con valores iniciales de los parámetros $a=a^{(0)}$ y $b=b^{(0)}$ elegidos al azar de alguna distribución de probabilidades, para luego iterar sobre la época de entrenamiento $t$ según\n",
    "\n",
    "$$ a^{(t+1)} = a^{(t)} - \\eta \\frac{\\partial L^{(t)}}{\\partial a}(x,y;a^{(t)},b^{(t)}) $$\n",
    "\n",
    "$$ b^{(t+1)} = b^{(t)} - \\eta \\frac{\\partial L^{(t)}}{\\partial b}(x,y;a^{(t)},b^{(t)}) $$\n",
    "\n",
    "donde el $\\eta$ tal que $0<\\eta\\ll 1$, es la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos los parámetros \"a\" y \"b\" con valores elegidos al azar de una distribución normal\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(1)\n",
    "b = np.random.randn(1)\n",
    "\n",
    "print(f\"Iniciales a={a},b={b}\")\n",
    "\n",
    "# Seteamos la tasa de aprendizaje (learning rate eta)\n",
    "lr = 1e-1\n",
    "\n",
    "# Definimos el número de épocas de entrenamiento\n",
    "n_epochs = 1000\n",
    "\n",
    "# Iteramos sobre épocas de entrenamiento\n",
    "for epoch in range(n_epochs):\n",
    "    # Calculamos las predicciones del modelo sobre el conjunto de entrenamiento\n",
    "    yhat = a + b * x_train\n",
    "    \n",
    "    # Calculamos el error de la predicción\n",
    "    error = (y_train - yhat)\n",
    "    # Calculamos la función de pérdida, en este caso, el error cuadrático medio (Mean Squared Error)\n",
    "    loss = (error ** 2).mean()\n",
    "    \n",
    "    # Calculamos el gradiente de la función de pérdida con respecto a los parámetros; \"a\" y \"b\" en este caso\n",
    "    a_grad = -2 * error.mean()\n",
    "    b_grad = -2 * (x_train * error).mean()\n",
    "    \n",
    "    # Actualizamos los valores de los parámetros usando el gradiente y la tasa de aprendizaje\n",
    "    a = a - lr * a_grad\n",
    "    b = b - lr * b_grad\n",
    "\n",
    "# Imprimimos los valores de \"a\" y \"b\" que resultan del ajuste\n",
    "print(f\"Ajustados a={a},b={b}\")\n",
    "\n",
    "# Corroboramos que todo anda bien, comparando con el ajuste proveido por scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "print(f\"Check     a={linr.intercept_},b={linr.coef_[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 2: idem, pero con PyTorch.\n",
    "Convenientemente, PyTorch provee de `torch.autograd`, un motor de diferenciación automática para calcular gradientes.\n",
    "\n",
    "Para ello, en este ejemplo tenemos que decirle a torch que `a` y `b` son tensores que requieren gradientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuestros datos estan en arrays de numpy.\n",
    "# Los transformamos, entonces, a tensores de PyTorch.\n",
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# Inicializamos los parámetros \"a\" y \"b\" de manera similar a como lo hicimos con la versión numpy.\n",
    "# Como aplicaremos el método del descenso por el gradiente sobre estos parámetros usando las funcionalidades\n",
    "# proveídas por PyTorch, seteamos la opción \"requires_grad\" de estos tensores a \"True\".\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "print(f\"Iniciales a={a.item()},b={b.item()}\")\n",
    "#print(f\"Iniciales a={a},b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenemos el modelo con un optimizador personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float) #, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float) #, device=device)\n",
    "print(f\"Iniciales a={a.item()},b={b.item()}\")\n",
    "\n",
    "# Iteramos sobre épocas de entrenamiento\n",
    "for epoch in range(n_epochs):\n",
    "    # Calculamos las predicciones del modelo, el error y la función de pérdida.\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Ya no necesitamos calcular gradientes de manera manual!\n",
    "    # a_grad = -2 * error.mean()\n",
    "    # b_grad = -2 * (x_tensor * error).mean()\n",
    "    \n",
    "    # Basta con decirle a PyTorch que llame al método backward() del tensor del cual queremos calcular el gradiente.\n",
    "    # En este caso, dicho tensor es \"loss\"; la función de pérdida.\n",
    "    loss.backward()\n",
    "    # Veamos las componentes del gradiente que obtuvimos en la presente época\n",
    "    print(f\"epoch={epoch} a.grad={a.grad},b.grad={b.grad}\")    \n",
    "    \n",
    "    # Para actualizar el valor de los parámetros, \"a\" y \"b\" en este caso, tenemos que desactivar el\n",
    "    # cálculo automático de gradientes.\n",
    "    # Esto es por la manera en que PyTorch está construido.\n",
    "    with torch.no_grad():\n",
    "        a -= lr * a.grad\n",
    "        b -= lr * b.grad\n",
    "    \n",
    "    # PyTorch no resetea a cero los valores de las componentes del gradiente, sinó que procede de\n",
    "    # manera acumulativa, ya que es conveniente por diferentes razones. \n",
    "    # Por ende, tenemos que decirle explícitamente que resetee los valores a cero.\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "# Imprimimos los valores ajustados\n",
    "print(f\"Ajustados a={a.item()},b={b.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que hemos usado `with torch.no_grad()` al momento de actualizar los valores de los parámetros `a` y `b`.\n",
    "\n",
    "Esto es así, porque de otra manera deberíamos cambiar el valor de `a.grad` y `b.grad` al actualizar los valores de `a` y `b`.\n",
    "Por alguna razón, a PyTorch no le gusta esto (quizás para evitar evalauciones ciruclares) y, por ende, si querémos actualizar los valores de `a` y `b`, tenemos que decirle primero a PyTorch que desactive la actualización automática de los gradientes.\n",
    "\n",
    "PyTorch calcula los gradientes de forma acumulativa.\n",
    "Por ello, cada vez que usamos los gradientes para actualizar los parámetros, luego debemos resetear a 0 los gradientes usando, por ejemplo, el método `.zero()`.\n",
    "\n",
    "En PyTorch los gradientes son actualizados tal como es especificado por el grafo computacional determinado por el modelo que uno define\n",
    "\n",
    "![](comp-graph.png \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A estos gráficos de arriba se los puede generar con torchviz\n",
    "#make_dot(yhat)\n",
    "#make_dot(error)\n",
    "#make_dot(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo 3: entrenando modelos con el optimizador proveido por PyTorch.\n",
    "\n",
    "Además del cálculo automático de gradientes, PyTorch provee de un optimizador que se encarga de la actualización automática de parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al igual que antes, inicializamos los parámetros \"a\" y \"b\" con valores aleatorios.\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float) #, device=device)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float) #, device=device)\n",
    "print(f\"Iniciales a={a.item()},b={b.item()}\")\n",
    "\n",
    "# Definimos la tasa de aprendizaje y el número de épocas de entrenamiento\n",
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "# Instanciamos un optimizador tipo Stochastic Gradient Descent (SGD) para optimizar los valores de los parámetros.\n",
    "# Notar que tenemos que especificarle cuales tensores son los parámetros sobre los cuales queremos optimizar.\n",
    "optimizer = optim.SGD([a, b], lr=lr)\n",
    "\n",
    "# Iteramos sobre épocas de entrenamiento\n",
    "for epoch in range(n_epochs):\n",
    "    # Calculamos predicciones, errores y la pérdida (error)\n",
    "    yhat = a + b * x_train_tensor\n",
    "    error = y_train_tensor - yhat\n",
    "    loss = (error ** 2).mean()\n",
    "\n",
    "    # Le pedimos a PyTorch que calcule el gradiente de la función \"pérdida\".\n",
    "    loss.backward()    \n",
    "    \n",
    "    # Ya no necesitamos actualizar los valores de los parámetros a mano...\n",
    "    # with torch.no_grad():\n",
    "    #     a -= lr * a.grad\n",
    "    #     b -= lr * b.grad\n",
    "    # En cambio, invocamos al optimizador para que lo haga\n",
    "    optimizer.step()\n",
    "    \n",
    "    # De la misma manera, ya no necesitamos resetear a cero los valores de las componentes del gradiente...\n",
    "    # a.grad.zero_()\n",
    "    # b.grad.zero_()\n",
    "    # En cambio, invocamos al optimizador para que lo haga\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "# Imprimimos los valores ajustados de los parámetros\n",
    "print(f\"Ajustados a={a.item()},b={b.item()}\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
