{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjuntos de datos de entrenamiento, validación y prueba\n",
    "\n",
    "**Refs**\n",
    "\n",
    "https://www.geeksforgeeks.org/training-neural-networks-with-validation-using-pytorch/\n",
    "\n",
    "https://towardsdatascience.com/using-machine-learning-to-predict-fitbit-sleep-scores-496a7d9ec48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from torchviz import make_dot\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Usando el dispositivo {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos una familia de redes neuronales $y = f_a(x;w_a)$ de distintas arquitecturas $a$.\n",
    "Aquí, $x$ denota la entrada (ej. features) de la red, $y$ la salida (ej. labels) y $w_a$ los parámetros o pesos sinápticos de la misma.\n",
    "\n",
    "Redes de distintas arquitecturas pueden pueden aprender datasets de distintas estructuras.\n",
    "En particular, redes de distintas arquitecturas pueden tener distintos números de parámetros y por ende pueden aprender datasets de distintas complejidades.\n",
    "\n",
    "Sabemos que redes demasiado simples (con pocos parámetros) no logran aprender datasets suficientemente complejos, y que redes demasiado complejas tienden a sobrefitear datos.\n",
    "Entonces, nos interesa encontrar aquella red de la familia, que mejor se desempeñe con los datos a disposición, aprendiendo correctamente los datos de entrenamiento, pero también generalizando sin sobrefitear sobre datos de validación.\n",
    "Para ello, dividimos el conjunto de datos a disposición (el cuál se supone estar compuesto de muestras generadas de manera estadísticamente independiente) en tres conjuntos:\n",
    "\n",
    "1. el conjunto de entrenamiento (training),\n",
    "\n",
    "2. el conjunto de validación (validation), y\n",
    "\n",
    "3. el conjunto de testeo (test).\n",
    "\n",
    "Luego, para encontrar la red de arquitectura más conveniente, realizamos el siguiente procedimiento para cada arquitectura $a$:\n",
    "\n",
    "1. Entrenamos la red $f_a(x,w_a)$ optimizando con respecto a $w_a$ sobre las muestras $x$ obtenidas de dataset de entrenamiento, y utilizando la función de pérdida de nuestra preferencia. Esto resulta en valores \"optimos\" de los parámetros $\\hat{w}_a$, de manera que $f_a(x,\\hat{w}_a)$ constituye la red entrenada.\n",
    "\n",
    "2. Luego, usando métricas de nuestra preferencia (ej. la función de pérdida), evaluamos $f_a(x,\\hat{w}_a)$ sobre el conjunto de validación, para ver cuán bien generaliza la red ya entrenada.\n",
    "\n",
    "Luego, elegimos la arquitectura $\\hat{a}$ que haya dado los mejores resultados durante el paso de validación 2.\n",
    "Finalmente, caracterizamos las bondades de nuestra elección $f_{\\hat{a}}(x;w_{\\hat{a}})$ evaluándola sobre el conjunto de prueba (test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo con FashionMNIST y una red multicapa de sólo una capa oculta.\n",
    "Para ello, comenzamos por crear los conjuntos de entrenamiento, validación y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La primera vez esto tarda un rato ya que tiene que bajar los datos de la red.\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = datasets.MNIST('', train = True, transform = transforms, download = True)\n",
    "#train_dataset,valid_dataset = random_split(train_dataset,[50000,10000])\n",
    "indices = torch.arange(3000)\n",
    "train_dataset = Subset(train_dataset,indices)\n",
    "train_dataset,valid_dataset = random_split(train_dataset,[2000,1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset),len(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego definimos la red neuronal.\n",
    "Esta es un perceptron con una capa oculta de tamaño arbitrario $n$. \n",
    "En este ejemplo, dicho $n$ es el único grado de libertad que dejamos variar, de entre todos los que definen la arquitectura de la red.\n",
    "En otras palabras, nuestra familia estará compuesta de redes con capas ocultas de distintos tamaños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,n=128):\n",
    "        super(Net,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(28*28,n)\n",
    "        self.linear2 = nn.Linear(n,n)\n",
    "        self.linear3 = nn.Linear(n,10)\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementamos las funciones para entrenar, validar y testear un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la función de entrenamiento\n",
    "def train_loop(dataloader,model,loss_fn,optimizer,verbose_each=32):  \n",
    "    # Calculamos cosas utiles que necesitamos\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    # Seteamos el modelo en modo entrenamiento. Esto sirve para activar, por ejemplo, dropout, etc. durante la fase de entrenamiento.\n",
    "    model.train()\n",
    "    # Pasamos el modelo la GPU si está disponible.        \n",
    "    model = model.to(device)    \n",
    "    # Iteramos sobre lotes (batchs)\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        # Pasamos los tensores a la GPU si está disponible.\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)      \n",
    "        # Calculamos la predicción del modelo y la correspondiente pérdida (error)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # Backpropagamos usando el optimizador proveido.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Imprimimos el progreso cada 100 batchs\n",
    "        if batch % verbose_each*len(X) == 0:\n",
    "            loss   = loss.item()\n",
    "            sample = batch*len(X) # Número de batch * número de muestras en cada batch\n",
    "            print(f\"batch={batch} loss={loss:>7f}  muestras-procesadas:[{sample:>5d}/{num_samples:>5d}]\")\n",
    "            \n",
    "# De manera similar, definimos la función de validación y testeo\n",
    "def test_loop(dataloader,model,loss_fn):\n",
    "    num_samples = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    avrg_loss    = 0\n",
    "    frac_correct = 0\n",
    "    # Seteamos el modelo en modo evaluacion. Esto sirve para desactivar, por ejemplo, dropout, etc. cuando no estamos en una fase de entrenamiento.\n",
    "    model.eval()\n",
    "    # Pasamos el modelo la GPU si está disponible.    \n",
    "    model = model.to(device)    \n",
    "    # Para validar, desactivamos el cálculo de gradientes.\n",
    "    with torch.no_grad():\n",
    "        # Iteramos sobre lotes (batches)\n",
    "        for X,y in dataloader:\n",
    "            # Pasamos los tensores a la GPU si está disponible.\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)           \n",
    "            # Calculamos las predicciones del modelo...\n",
    "            pred = model(X)\n",
    "            # y las correspondientes pérdidas (errores), los cuales vamos acumulando en un valor total.\n",
    "            avrg_loss += loss_fn(pred,y).item()\n",
    "            # También calculamos el número de predicciones correctas, y lo acumulamos en un total.\n",
    "            frac_correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "\n",
    "    # Calculamos la pérdida total y la fracción de clasificaciones correctas, y las imprimimos.\n",
    "    avrg_loss    /= num_batches\n",
    "    frac_correct /= num_samples\n",
    "    print(f\"Test Error: \\n Accuracy: {frac_correct:>0.5f}, Avg. loss: {avrg_loss:>8f} \\n\")\n",
    "    return avrg_loss,frac_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos, entrenamos y validamos redes de la familia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definimos hiperparámetros de entrenamiento\n",
    "learning_rate = 1e-3\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "# Definimos familia\n",
    "family = [32,64,128]\n",
    "\n",
    "# Creamos DataLoader's para cada dataset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(test_dataset,  batch_size=batch_size)\n",
    "\n",
    "# Creamos una funcion de perdida\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Iteramos sobre (algunos elementos de) la familia de modelos\n",
    "performance = {}\n",
    "for n in family:\n",
    "    print(f\"Model of size n={n}\\n-------------------------------\")    \n",
    "    model = Net(n)\n",
    "    # Creamos un optimizador (un Stochastic Gradient Descent en este caso) para el modelo en cuestion.\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "    # Entrenamos el modelo por varias epocas, registrando al final\n",
    "    avrg_loss    = None\n",
    "    frac_correct = None\n",
    "    performance_n  = {}\n",
    "    performance[n] = performance_n\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch={epoch} n={n}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader,model,loss_fn,optimizer)\n",
    "        avrg_loss,frac_correct = test_loop(valid_dataloader,model,loss_fn)\n",
    "        performance_epoch = {\"avrg_loss\":avrg_loss,\"frac_correct\":frac_correct,\"model\":model}\n",
    "        performance_n[epoch] = performance_epoch\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visalicemos para elegir una arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos la arquitectura elegida en el dataset de prueba, comparando con lo que da en el dataset de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in family:\n",
    "    chosen = performance[n][max(performance[n].keys())]\n",
    "    avrg_loss    = chosen[\"avrg_loss\"]\n",
    "    frac_correct = chosen[\"frac_correct\"]\n",
    "    model        = chosen[\"model\"]    \n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"n = {n}\")\n",
    "    avrg_loss_prueba,frac_correct_prueba = test_loop(test_dataloader,model,loss_fn)\n",
    "    print(f\"avrg_loss_valid  = {avrg_loss}\\t frac_correct_valid  = {frac_correct}\")\n",
    "    print(f\"avrg_loss_prueba = {avrg_loss_prueba}\\t frac_correct_prueba = {frac_correct_prueba}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
