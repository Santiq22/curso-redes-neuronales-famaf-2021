{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial de PyTorch\n",
    "\n",
    "## Instalación\n",
    "\n",
    "Instalaremos PyTorch usando Conda y sin soporte para CUDA en Linux.\n",
    "Abrir una terminal o cónsola de bash.\n",
    "\n",
    "1. Activar conda o miniconda con Python 3\n",
    "\n",
    "        > source ~/miniconda3/bin/activate\n",
    "        \n",
    "2. Crear un nuevo environment en conda y activarlo\n",
    "\n",
    "        > conda create --name env-pytorch\n",
    "        > conda activate env-pytorch\n",
    "        \n",
    "3. Instalar `pytorch`. Para ello, ir a la página\n",
    "\n",
    "    https://pytorch.org/get-started/locally/#start-locally\n",
    "    \n",
    "   y elegir:\n",
    "\n",
    "        PyTorch build      -> Stable\n",
    "        Your OS            -> Linux\n",
    "        Package            -> Conda\n",
    "        Language           -> Python\n",
    "        Compute platform   -> CPU\n",
    "    \n",
    "   Esto generará un comando debajo que deberemos ingresar en el environment de conda recientemente activado\n",
    "\n",
    "        (env-pytorch)> conda install pytorch torchvision torchaudio cpuonly -c pytorch\n",
    "        \n",
    "   Notar que, además de instalar `pytorch`, también instalará `torchvision` y `torchaudio`. Estos otros dos paquetes incluyen, entre otras cosas, datasets con los cuales experimentar.\n",
    "\n",
    "4. Para completar el environment, instalaremos además `numpy`, `scipy`, `scikit-learn`, `jupyter`, `matplotlib` y `pandas`\n",
    "        \n",
    "        (env-pytorch)> conda install -c anaconda numpy \n",
    "        (env-pytorch)> conda install -c conda install -c anaconda scipy \n",
    "        (env-pytorch)> conda install -c anaconda scikit-learn \n",
    "        (env-pytorch)> conda install -c conda install -c anaconda jupyter\n",
    "        (env-pytorch)> conda install -c conda-forge matplotlib\n",
    "        (env-pytorch)> conda install -c anaconda pandas\n",
    "        \n",
    "## Referencias\n",
    "\n",
    "    https://pytorch.org/tutorials/beginner/basics/intro.html\n",
    "    https://wiki.pathmind.com/comparison-frameworks-dl4j-tensorflow-pytorch#tensorflow\n",
    "    https://blog.paperspace.com/ultimate-guide-to-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeamos la instalación\n",
    "\n",
    "Nos basamos en\n",
    "\n",
    "    https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bajamos datos necesarios proveidos por PyTorch para hacer unos tests\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determinamos si existe soporte CUDA o no.\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un modelo de red neuronal\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizamos los parámetros del modelo.\n",
    "# Para ello, necesitamos definir una funcion error.\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para un ciclo de entrenamiento, el modelo hace predicciones sobre el dataset de entrenamiento \n",
    "# (el cuál es) alimentado en lotes (batches) y retroalimentamos (backpropagates) el error de las predicciones\n",
    "# para ajustar los parámetros del modelo.\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También chequeamos el desempeño (performance) del modelo ante el dataset de testeo, para asegurarnos\n",
    "# que está aprendiendo.\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El proceso de entrenamiento transcurre durante varias iteraciones de épocas (epochs)\n",
    "# Durante cada época, el modelo busca ajustar el valor de los parámetros con el fin de mejorar las predicciones.\n",
    "# Imprimimos la precisión y el error de la predicción del modelo en cada época; esperamos ver que la\n",
    "# precisión aumenta y el error decrece en cada iteración.\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
